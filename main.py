#coding:utf-8

"""

     * æ¥½æ›²é–“é¡ä¼¼åº¦ã®è¨ˆç®— -> ãƒªã‚¹ãƒˆã‚’ä½œã£ã¦å†ç”Ÿ
     * log2(æ›²æ•°)ã‚’ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§æŒ‡å®šã—ã¦è§£æã‚’è¡Œã†


"""

from collections import OrderedDict
import pydub as dub
from pydub.playback import play
from pprint import pprint
from glob import glob
import os
import sys
import shutil
import librosa
import librosa.display
import numpy as np
import matplotlib.pyplot as plt
import tempfile as temp
import functions as fn
from typing import NamedTuple
import random
from tqdm import tqdm
import datetime

class Mix:
    """

     éŸ³æ¥½å†ç”Ÿãƒ»ãƒŸãƒƒã‚¯ã‚¹ã‚¯ãƒ©ã‚¹

     Attributes:
        self.wav_name (ãƒªã‚¹ãƒˆ): tmpç›´ä¸‹ã®wavãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ.
        self.path (ãƒªã‚¹ãƒˆ): tmpç›´ä¸‹ã®wavãƒ•ã‚¡ã‚¤ãƒ«(çµ¶å¯¾ãƒ‘ã‚¹)ã®ãƒªã‚¹ãƒˆ.

    """

    def __init__(self, songDict, playList = None):
        """ã‚¤ãƒ‹ã‚·ãƒ£ãƒ©ã‚¤ã‚¶

         éŸ³æ¥½ãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã®åˆæœŸåŒ–

        Args:
            songDict (é †åºã¤ãè¾æ›¸): [ãƒ•ã‚¡ã‚¤ãƒ«å - ((BPM,beats),Key)]
            playList (ãƒªã‚¹ãƒˆ): æ›²åã®ãƒªã‚¹ãƒˆ

        Note:
            playListã‚’æŒ‡å®šã—ãªã„å ´åˆã¯ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®æ›²ã‚’os.listdirã§å–å¾—ã—ãŸé †ç•ªã§å†ç”Ÿ

        """
        self.songDict = songDict
        if playList is None:
            self.wav_name = os.listdir(wavAudioPath)
            self.playList = self.wav_name
        else:
            self.playList = playList
        print("\nMixã‚’initã—ãŸ")
        print("self.playList : ")
        pprint(self.playList)
        print("\nåˆè¨ˆ" + str(len(self.playList)) + "æ›²")
        print("2^å®Ÿè¡Œæ™‚å¼•æ•° : " + str(songNum))

    def play(self):
        for i in self.playList:
            self.song = dub.AudioSegment.from_wav(i)
            print(type(self.song))
            play(self.song)
        self.play()

    def MIX(self):
        self.silenceDuration = self.songDict[self.playList[0]].BPM.beats[15] + dub.AudioSegment.from_wav(self.playList[-1]).duration_seconds - self.songDict[self.playList[-1]].BPM.beats[-1]
        for song in self.playList:
            self.silenceDuration += self.songDict[song].BPM.beats[-1]
            self.silenceDuration -= self.songDict[song].BPM.beats[15]
        self.mixDown = dub.AudioSegment.silent(duration=(self.silenceDuration + 1) * 1000)
        # æ‹ä½ç½®ã‚’åˆã‚ã›ã¦æ¥½æ›²ã‚’ã‚ªãƒ¼ãƒãƒ¼ãƒ¬ã‚¤ã™ã‚‹
        self.startPosition = 0 # æ›²ã®å†ç”Ÿé–‹å§‹ä½ç½®[sec]
        self.prevSongEndBeatPosition = 0 # æ›²ã®çµ‚äº†æ‹ä½ç½®[sec]
        self.fadeInDuration = 0 # æ¬¡ã®æ›²ã®ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ã‚’ã‹ã‘ã‚‹æ™‚é–“[sec]
        self.fadeOutDuration = 0 # æ›²ã®ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆã‚’ã‹ã‘ã‚‹æ™‚é–“[sec]
        self.startPositionDict = {} # é–‹å§‹ä½ç½®ã‚’è¨˜éŒ²ã—ã¦ãŠã[sec]
        for i, song in tqdm(enumerate(self.playList)):
            self.song_as = dub.AudioSegment.from_wav(song)
            self.fadeOutDuration = self.song_as.duration_seconds - self.songDict[song].BPM.beats[-16] # å†ç”Ÿæ™‚é–“[sec] - çµ‚äº†ã‹ã‚‰15æ‹ç›®ã®ä½ç½®
            self.fadeInDuration = self.songDict[song].BPM.beats[15]
            if i is not 0 and i is not len(self.playList)-1: # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆã€ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ã‚’é©ç”¨
                self.song_as = self.song_as.fade_in(duration=int(self.fadeInDuration * 1000))
                self.song_as = self.song_as.fade_out(duration=int(self.fadeOutDuration * 1000))
            elif i is 0: # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆã®ã¿é©ç”¨
                self.song_as = self.song_as.fade_out(duration=int(self.fadeOutDuration * 1000))
            elif i is len(self.playList)-1: # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³ã®ã¿é©ç”¨
                self.song_as = self.song_as.fade_in(duration=int(self.fadeInDuration * 1000))
            if i is not 0: # æœ€åˆã®æ›²ã®ã¿0[sec]ã‹ã‚‰å†ç”Ÿ
                self.startPosition = self.prevSongEndBeatPosition - self.songDict[song].BPM.beats[15]
            self.mixDown = self.mixDown.overlay(self.song_as, position=self.startPosition*1000, loop=False, times=1, gain_during_overlay=0)
            self.startPositionDict[song] = self.startPosition
            self.prevSongEndBeatPosition = self.startPosition + self.songDict[song].BPM.beats[-1]
        return

    def export(self):
        #chunks = split_on_silence(self.mixDown, min_silence_len=3000, silence_thresh=-40, keep_silence=1000)
        self._exPath = "/Users/hmori/ChromagramSample3/MixDown"
        if not os.path.isdir(self._exPath):
            os.makedirs(self._exPath)
        self.mixDown.export(self._exPath + "/" + "MixDownğŸ˜ˆ.mp3", format="mp3")
        #chunks[0].export(self._exPath + "/" + "MixDownğŸ˜ˆ.mp3", format="mp3")
        print("\nSuccessful export!ğŸ‰ğŸº : " + self._exPath + "/" + "MixDownğŸ˜ˆ.mp3")
        return

class Analyse:

    def __init__(self):
        self.dir_path = wavAudioPath
        self.wav_path = self.dir_path + '/*.wav'
        self.file_names = glob(self.wav_path)
        del self.file_names[songNum:]
        print("è§£æã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«")
        pprint(self.file_names)
        self.file_path = self.file_names
        self.bpm = {}
        self.key = {}
        self.chroma = {}
        # ã‚¹ã‚±ãƒ¼ãƒ«ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ã‚¯ãƒˆãƒ«
        # ãƒ¡ã‚¸ãƒ£ãƒ¼ã¨ãƒã‚¤ãƒŠãƒ¼ã‚’åŒºåˆ¥ã—ãªã„ãƒ€ã‚¤ã‚¢ãƒˆãƒ‹ãƒƒã‚¯ã‚¹ã‚±ãƒ¼ãƒ«ã®ã¿(ãƒ¡ã‚¸ãƒ£ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«ã®ã¿ã®12ã‚­ãƒ¼)ã‚’è€ƒãˆã‚‹
        # é †ç•ªã‚’ä¿ã¡ãŸã„ã®ã§OrderedDict
        self.scale_dic = OrderedDict()
        self.scale = ["C", "Db", "D", "Eb", "E", "F", "Gb", "G", "Ab", "A", "Bb", "B"]
        for i in range(len(self.scale)):
                self.scale_dic[self.scale[i]] = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
                self.scale_dic[self.scale[i]][(i+1)%12] = 0
                self.scale_dic[self.scale[i]][(i+3)%12] = 0
                self.scale_dic[self.scale[i]][(i+6)%12] = 0
                self.scale_dic[self.scale[i]][(i+8)%12] = 0
                self.scale_dic[self.scale[i]][(i+10)%12] = 0

    def analyse_bpm(self):
        '''

        å‚è€ƒ :
        https://qiita.com/yuuki__/items/4bc16ae439de46cd0d76
        https://www.wizard-notes.com/entry/music-analysis/compute-bpm-with-librosa

        https://librosa.github.io/librosa/generated/librosa.beat.tempo.html#librosa.beat.tempo
        https://librosa.github.io/librosa/generated/librosa.beat.beat_track.html

        '''
        for file_name,path in tqdm(zip(self.file_names,self.file_path)):
            if file_name not in self.bpm:
                self.music, self.sr = librosa.load(path)
                self._bpm, self._beatsPosition = librosa.beat.beat_track(self.music,self.sr)
                self.beatsPosition = librosa.frames_to_time(self._beatsPosition)
                self.bpm[file_name] = BPM(self._bpm, self.beatsPosition)
            else:
                continue
        return self.bpm

    def calc_chroma(self):
        '''

        å‚è€ƒ : https://qiita.com/namaozi/items/31ea255ecc6a04320dfc

        '''
        for file_name,path in zip(self.file_names,self.file_path):
            if file_name not in self.chroma:
                # æ›²ã®1:00~1:30ã‚’æŠœãå‡ºã™(å‡¦ç†ãŒé‡ã„)
                # TODO: æ›²ã®ä¸­å¿ƒ30ç§’ã«ã™ã‚‹
                self.music, self.sr = librosa.load(path,offset=60.0, duration=30.0)
                # æ¥½éŸ³æˆåˆ†ã¨ãƒ‘ãƒ¼ã‚«ãƒƒã‚·ãƒ–æˆåˆ†ã«åˆ†é›¢
                harmonic, percussive = librosa.effects.hpss(self.music)
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®Chromaã‚’è¨ˆç®—
                self.allChroma = librosa.feature.chroma_cens(y=harmonic)
                self._chroma = np.zeros(12)
                '''
                # ãƒ—ãƒ­ãƒƒãƒˆ
                plt.figure(figsize=(12,4))
                librosa.display.specshow(allChroma, sr=self.sr, x_axis='time', y_axis='chroma', vmin=0, vmax=1)
                plt.title('Chromagram')
                plt.colorbar()
                plt.tight_layout()
                plt.show()
                '''
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã®Chromaã‚’1æ¬¡å…ƒ12éŸ³éšã«æŠ¼ã—è¾¼ã‚€
                for i in range(self.allChroma.shape[0]):
                    for j in range(self.allChroma.shape[1]):
                        self._chroma[i] += self.allChroma[i][j]
                self.chroma[file_name] = self._chroma
            else:
                continue
        return self.chroma

    def analyse_key(self):
        for file_name,path in tqdm(zip(self.file_names,self.file_path)):
            if file_name not in self.chroma:
                self.music, self.sr = librosa.load(path,offset=30.0, duration=30.0)
                harmonic, percussive = librosa.effects.hpss(self.music)
                self.allChroma = librosa.feature.chroma_cens(y=harmonic)
                self._chroma = np.zeros(12)
                for i in range(self.allChroma.shape[0]):
                    for j in range(self.allChroma.shape[1]):
                        self._chroma[i] += self.allChroma[i][j]
            # Chromaã¨ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ãŒæœ€å¤§ã«ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã‚’èª¿ã¹ã‚‹
            self.maximum = -100000
            self._key = ""
            for scale_index, (name, templateVec) in enumerate(self.scale_dic.items()):
                self.similarity = fn.cos_sim(self._chroma, templateVec)
                if self.similarity > self.maximum:
                    self.maximum = self.similarity
                    self._key = name
                    self.key[file_name] = self._key
                else:
                    continue
            else:
                continue
        return self.key

class Map:
    """

     æ¥½æ›²é–“é¡ä¼¼åº¦ã‚’ç®—å‡ºã€ä¿æŒã™ã‚‹ã‚¯ãƒ©ã‚¹

    Attributes:
        self.songmMap (2æ¬¡å…ƒé…åˆ—): æ›²ã‚’ãƒãƒ¼ãƒ‰ã¨è¦‹ç«‹ã¦ãŸæ¥½æ›²é–“è·é›¢ã®éš£æ¥è¡Œåˆ—.
        self.songList (1æ¬¡å…ƒé…åˆ—): å†ç”Ÿé †ã«ä¸¦ã¹ã‚‰ã‚ŒãŸæ›²åã®ãƒªã‚¹ãƒˆ.
        self.keyDist (2æ¬¡å…ƒé…åˆ—): ã‚­ãƒ¼é–“ã®ç›¸æ€§ã‚’è·é›¢ã¨ã—ã¦æ ¼ç´ã—ãŸéš£æ¥è·é›¢.

    """
    def __init__(self, songDict, param):
        """ã‚¤ãƒ‹ã‚·ãƒ£ãƒ©ã‚¤ã‚¶

         éš£æ¥è¡Œåˆ—ã®ç”Ÿæˆ
         æœ€çŸ­ãƒãƒŸãƒ«ãƒˆãƒ³è·¯ã®ç®—å‡ºã€ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã®ä½œæˆ

        Args:
            songDict: é †åºä»˜ããƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒª,[ãƒ•ã‚¡ã‚¤ãƒ«å - ((BPM,beats),Key)]
            param: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã®ã‚¿ãƒ—ãƒ«,(BPMã®é‡ã¿ã€Keyã®é‡ã¿)

        Todo:
            æœ€çŸ­ãƒãƒŸãƒ«ãƒˆãƒ³è·¯ã®é«˜é€Ÿè¨ˆç®—ã‚’å®Ÿè£…ã™ã‚‹

        """
        self.songMap = np.empty((len(songDict), len(songDict)))
        self.keyDist = np.empty((12,12))
        self.songDict = songDict
        self.param = param
        self.songListIndex = np.empty(len(songDict))
        self.playList = []

    def play_list(self):
        for i, s1 in enumerate(self.songDict.values()):
            for j, s2 in enumerate(self.songDict.values()):
                if i is not j:
                    self.songMap[i][j] = (abs(s1.BPM.BPM - s2.BPM.BPM) * 0.04 ) ** 1.2
                    self.songMap[i][j] += (1 - self.key_distance(s1.Key, s2.Key)) ** 1.2
                else :
                    self.songMap[i][j] = 10000

        self.songDict_list = []

        for song in self.songDict.keys():
            self.songDict_list.append(song)

        for idx, songIdx in enumerate(self.songListIndex):
            if idx is 0:
                self.songListIndex[idx] = random.randrange(len(self.songDict))
            else:
                li = []
                row_num = int(self.songListIndex[idx-1])
                sortedIdxArr = np.argsort(self.songMap[row_num])
                for sortedIdx in sortedIdxArr:
                    if sortedIdx not in self.songListIndex:
                        li.append(sortedIdx)
                    if len(li) >= 1:
                        break
                if len(li) is not 0:
                    self.songListIndex[idx] = random.choice(li)
                li.clear

        for songIdx in self.songListIndex:
            self.playList.append(self.songDict_list[int(songIdx)])

        return self.playList

    def key_distance(self, key1, key2):
        #ã€€å…±é€šã—ã¦ã„ã‚‹éŸ³éšã®æ•°ã®éš£æ¥è¡Œåˆ—
        self.scale = ["C", "Db", "D", "Eb", "E", "F", "Gb", "G", "Ab", "A", "Bb", "B"]
        self.keyDist = [[7, 2, 5, 4, 3, 6, 2, 6, 3, 4, 5, 2],
                        [2, 7, 2, 5, 4, 3, 6, 2, 6, 3, 4, 5],
                        [5, 2, 7, 2, 5, 4, 3, 6, 2, 6, 3, 4],
                        [4, 5, 2, 7, 2, 5, 4, 3, 6, 2, 6, 3],
                        [3, 4, 5, 2, 7, 2, 5, 4, 3, 6, 2, 6],
                        [6, 3, 4, 5, 2, 7, 2, 5, 4, 3, 6, 2],
                        [2, 6, 3, 4, 5, 2, 7, 2, 5, 4, 3, 6],
                        [6, 2, 6, 3, 4, 5, 2, 7, 2, 5, 4, 3],
                        [3, 6, 2, 6, 3, 4, 5, 2, 7, 2, 5, 4],
                        [4, 3, 6, 2, 6, 3, 4, 5, 2, 7, 2, 5],
                        [5, 4, 3, 6, 2, 6, 3, 4, 5, 2, 7, 2],
                        [2, 5, 4, 3, 6, 2, 6, 3, 4, 5, 2, 7]]
        return self.keyDist[self.scale.index(key1)][self.scale.index(key2)] / 7

    def printMap(self):
        print("songMap : ")
        print(self.songMap)

    def printList(self):
        print(self.playList)

class BPM(NamedTuple):
    BPM: np.float64
    beats: np.ndarray

class BPM_n_Key(NamedTuple):
    BPM: BPM
    Key: str

if __name__ == "__main__" :

    commandArg = sys.argv[1]

    for index in range(int(commandArg)):

        print("\nConversioning to wav file...")

        # æ›²æ•°(æŒ‡æ•°ãŒå®Ÿè¡Œæ™‚ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿)
        songNum = 2 ** index

        # make wav file directory
        wavAudioPath = "/Users/hmori/ChromagramSample3/waves"

        import time
        t0 = time.time()

        # instantiation analyser
        analyser = Analyse()

        # bpm analyse
        print("\nAnalyzing BPM...")
        bpm_list = analyser.analyse_bpm()

        t1 = time.time()

        # key analyse
        print("\nAnalyzing Key...")
        key_list = analyser.analyse_key()

        t2 = time.time()

        # song_dict: [ãƒ•ã‚¡ã‚¤ãƒ«å - ((BPM,beats),Key)]ã®é †åºä»˜ãè¾æ›¸
        song_dict = OrderedDict()
        for k, tp in bpm_list.items():
            song_dict[k] = BPM_n_Key(tp, key_list[k])

        t3 = time.time()

        # æ¥½æ›²é–“é¡ä¼¼åº¦ã®ãƒãƒƒãƒ—ã‚’ä½œæˆ
        print("\nAnalyzing music between similarity...")
        Map = Map(song_dict, (1,1))

        t4 = time.time()

        # æ›²é †ã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        print("\nDetermining playback order...")
        play_list = Map.play_list()
        print("æ›²æ•° : " + str(len(play_list)))

        t5 = time.time()

        # instantiation player
        mixer = Mix(song_dict,play_list)
        # MIXã‚’ä½œæˆ
        print("\nCreating Mix...")
        mixer.MIX()

        t6 = time.time()

        # MIXã‚’ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        print("\nExporting Mix...")
        mixer.export()

        t7 = time.time()

        # æœ€çµ‚çš„ã«å‡ºåŠ›ã™ã‚‹ãƒªã‚¹ãƒˆ
        # [æŒ‡æ•°][æ›²æ•°][BPMè§£æã«ã‹ã‹ã£ãŸæ™‚é–“][ã‚­ãƒ¼è§£æã«ã‹ã‹ã£ãŸæ™‚é–“][songDictä½œæˆã«ã‹ã‹ã£ãŸæ™‚é–“][ãƒãƒƒãƒ—ä½œæˆã«ã‹ã‹ã£ãŸæ™‚é–“]
        # [ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆç”Ÿæˆã«ã‹ã‹ã£ãŸæ™‚é–“][ãƒŸãƒƒã‚¯ã‚¹ã®ç”Ÿæˆã«ã‹ã‹ã£ãŸæ™‚é–“][ãƒŸãƒƒã‚¯ã‚¹ã®æ›¸ãå‡ºã—ã«ã‹ã‹ã£ãŸæ™‚é–“]
        timeList = []
        timeList.append(index)
        timeList.append(songNum)
        timeList.append(t1 - t0)
        timeList.append(t2 - t1)
        timeList.append(t3 - t2)
        timeList.append(t4 - t3)
        timeList.append(t5 - t4)
        timeList.append(t6 - t5)
        timeList.append(t7 - t6)

        print("timeList : ")
        print(timeList)
        dump_str = ",".join(map(str, timeList))

        resultFolderPath = "/Users/hmori/ChromagramSample3/dump"
        if not os.path.isdir(resultFolderPath):
            os.makedirs(resultFolderPath)
        with open(resultFolderPath + "/dump.txt",mode='a') as f:
            f.write("\n" + dump_str)

        print("\nFinish dumping resultsï¼ğŸ¥³: " + resultFolderPath+ "/" + "dump.txt")
